{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67b8e147",
   "metadata": {},
   "source": [
    "PHO Vinh-Son 3802052 <br>\n",
    "CHOI Esther 3800370"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cb51c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import os.path\n",
    "\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model as lin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import string\n",
    "\n",
    "#df,mf,b,smooth = (0.18, 10000, 0.134, [1, 2, 3, 4, 5, 6, 7, 8, 2])\n",
    "\n",
    "def conf(Y_Test,Y_hat):\n",
    "    confusion = np.zeros((2,2))\n",
    "    Y_hat = (Y_hat+1)//2\n",
    "    Y_Test = (Y_Test+1)//2\n",
    "    for i in range(Y_Test.size):\n",
    "        confusion[Y_Test[i],Y_hat[i]] +=1\n",
    "    return confusion\n",
    "    \n",
    "def f1(conf):\n",
    "    tp = conf[0,0]\n",
    "    false = conf[0,1] + conf[1,0]\n",
    "    return (tp/(tp+0.5*false))\n",
    "\n",
    "def load_movies(dirname):\n",
    "    \"\"\"\n",
    "    str -> list(str) * list(str) * list(str)\n",
    "    dirname = contient le dossier des avis positifs et negatifs (supposés appelés pos et neg)\n",
    "        et le fichier test supposé appelé \"testSentiment.txt\"\n",
    "    Retourne la liste des avis négatifs, la liste des avis positifs et la liste test\n",
    "    \"\"\"\n",
    "    postxts = []\n",
    "    negtxts = []\n",
    "    testtxts = []\n",
    "    \n",
    "    punc = string.punctuation  # recupération de la ponctuation\n",
    "    punc += '\\n\\r\\t'\n",
    "    \n",
    "    # avis positifs\n",
    "    dirpos = dirname+\"/pos\"\n",
    "    for filename in os.listdir(dirpos):\n",
    "        fpath = os.path.join(dirpos, filename) #dirname/pos/filename\n",
    "        f = codecs.open(fpath, 'r','utf-8') # pour régler le codage\n",
    "        t = f.read()\n",
    "        #t = t.translate(str.maketrans(punc, ' ' * len(punc))) #suppression de la ponctuation\n",
    "        postxts.append(t)\n",
    "        f.close()\n",
    "        \n",
    "    # avis négatifs\n",
    "    dirneg = dirname+\"/neg\"\n",
    "    for filename in os.listdir(dirneg):\n",
    "        fpath = os.path.join(dirneg, filename) #dirname/pos/filename\n",
    "        f = codecs.open(fpath, 'r','utf-8') # pour régler le codage\n",
    "        t = f.read()\n",
    "        #t = t.translate(str.maketrans(punc, ' ' * len(punc))) #suppression de la ponctuation\n",
    "        negtxts.append(t)\n",
    "        f.close()\n",
    "    \n",
    "    # fichier test\n",
    "    ftest = dirname+\"/testSentiment.txt\"\n",
    "    f = codecs.open(ftest, 'r','utf-8') # pour régler le codage        \n",
    "    testtxts = f.readlines()\n",
    "    \n",
    "    while True:\n",
    "        t = f.readline()\n",
    "        if not t: # empty line = eof\n",
    "            break\n",
    "        #t = t.translate(str.maketrans(punc, ' ' * len(punc))) #suppression de la ponctuation\n",
    "        testtxts.append(t)\n",
    "    \n",
    "    return postxts,negtxts,testtxts\n",
    "\n",
    "def load_pres_T(fname):\n",
    "    alltxts_T = []\n",
    "    s=codecs.open(fname, 'r','utf-8') # pour régler le codage\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*>(.*)\",\"\\\\1\",txt)\n",
    "        alltxts_T.append(txt)\n",
    "    return alltxts_T\n",
    "\n",
    "def crossval(alltxts,alllabs,cv = 5,shuffle = False, seed = 42):\n",
    "    ind = np.array([i for i in range(alllabs.size)])\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(ind)\n",
    "    splitind = np.array_split(ind, cv)\n",
    "    lcrossval = []\n",
    "    for indices in splitind:\n",
    "        lcrossval.append((alltxts[indices],np.delete(alltxts,indices),alllabs[indices],np.delete(alllabs,indices)))\n",
    "    return lcrossval\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ef2346",
   "metadata": {},
   "source": [
    "## Mise en forme des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851326d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainset(postxts, negtxts, mode):\n",
    "    \"\"\"\n",
    "    list(str) * list(str) -> list(str) * list(str)\n",
    "    mode = concat, blocs, random\n",
    "    Retourne l'ensemble de train défini selon le mode passé en paramètre\n",
    "    \"\"\"\n",
    "    if mode == \"concat\":\n",
    "        alltxts = postxts + negtxts\n",
    "        alllabs = [1 for i in range(len(postxts))] + [-1 for i in range(len(negtxts))]\n",
    "    \n",
    "    elif mode == \"blocs\":\n",
    "        n = int((len(postxts)//10)*2) #nombre de blocs de 10\n",
    "        alltxts = []\n",
    "        alllabs = []\n",
    "        for i in range(n):\n",
    "            if i%2 == 0:\n",
    "                alltxts = alltxts + postxts[i:i+10]\n",
    "                alllabs = alllabs + [1 for j in range(10)]\n",
    "            else:\n",
    "                alltxts = alltxts + negtxts[i:i+10]\n",
    "                alllabs = alllabs + [-1 for j in range(10)]\n",
    "                \n",
    "    elif mode == \"random\":\n",
    "        t = postxts + negtxts\n",
    "        l = [1 for i in range(len(postxts))] + [-1 for i in range(len(negtxts))]\n",
    "        tmp = np.array([t,l])\n",
    "        np.random.shuffle(tmp.T)\n",
    "        alltxts = tmp[0,:]\n",
    "        alllabs = tmp[1,:].astype(int)\n",
    "                \n",
    "    else:\n",
    "        print(\"mode invalide\")\n",
    "        return\n",
    "    \n",
    "    return np.array(alltxts), np.array(alllabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba155d",
   "metadata": {},
   "source": [
    "## Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1469bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_pred_param(df,mf,fname = \"movies1000\", trainsetmode = \"random\",cv_fold = 5,vectorizer = TfidfVectorizer, classifier = lin.LogisticRegression):\n",
    "    postxts,negtxts,testtxts = load_movies(fname)\n",
    "    alltxts, alllabs = trainset(postxts,negtxts,trainsetmode)\n",
    "    \n",
    "    lcrossval = crossval(alltxts,alllabs,cv = cv_fold,shuffle = True, seed = 42)\n",
    "    liste_score_bonneclassif = []\n",
    "    \n",
    "    for X_Test, X_Train, Y_Test, Y_Train in lcrossval:\n",
    "\n",
    "        #init\n",
    "        vectorizer2 = vectorizer(analyzer='word',max_df = df, max_features = mf,stop_words='english', lowercase = True, token_pattern=r\"(?u)\\b\\w\\w+\\b|!|.|\\?|\\\"|\\'\")\n",
    "        X_VTr = vectorizer2.fit_transform(X_Train)\n",
    "        X_VTe = vectorizer2.transform(X_Test)\n",
    "        clf = classifier(max_iter = 300)\n",
    "        \n",
    "        #fit\n",
    "        clf.fit(X_VTr, Y_Train)\n",
    "        \n",
    "        #predict\n",
    "        Y_hat_b = clf.predict(X_VTe)\n",
    "\n",
    "        #scoring taux de bonne classif\n",
    "        c = 0\n",
    "        for i in range(Y_Test.size):\n",
    "            if Y_Test[i] == Y_hat_b[i]:\n",
    "                c += 1\n",
    "        liste_score_bonneclassif.append(c/Y_Test.size)\n",
    "        \n",
    "    liste_score_bonneclassif = np.array(liste_score_bonneclassif)\n",
    "    return liste_score_bonneclassif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "773bead6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825\n"
     ]
    }
   ],
   "source": [
    "df, mf = (0.28, 9500)\n",
    "l = score_pred_param(df,mf)\n",
    "print(l.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509212aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
